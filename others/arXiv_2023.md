*Rubèn Tito, Dimosthenis Karatzas, Ernest Valveny*, **“Hierarchical multimodal transformers for multi-page DocVQA”** [[HOME Page]](https://arxiv.org/abs/2212.05935) [[PDF]](https://arxiv.org/abs/2212.05935)



*Hosein Hasanbeig, Hiteshi Sharma, Leo Betthauser, Felipe Vieira Frujeri, Ida Momennejad*, **“Allure: A systematic protocol for auditing and improving llm-based evaluation of text using iterative in-context-learning,”** [[HOME Page]](https://arxiv.org/abs/2309.13701) [[PDF]](https://arxiv.org/pdf/2309.13701)



*Mingqi Gao, Jie Ruan, Renliang Sun, Xunjian Yin, Shiping Yang, Xiaojun Wan*, **“Human-like summarization evaluation with Chat-GPT”** [[HOME Page]](https://arxiv.org/abs/2304.02554) [[PDF]](https://arxiv.org/pdf/2304.02554)



*Xinghua Zhang, Bowen Yu, Haiyang Yu, Yangyu Lv, Tingwen Liu, Fei Huang, Hongbo Xu, Yongbin Li*, **“Wider and deeper LLM networks are fairer LLM evaluators”** [[HOME Page]](https://arxiv.org/abs/2308.01862) [[PDF]](https://arxiv.org/pdf/2308.01862)



*Tianlu Wang, Ping Yu, Xiaoqing Ellen Tan, Sean O'Brien, Ramakanth Pasunuru, Jane Dwivedi-Yu, Olga Golovneva, Luke Zettlemoyer, Maryam Fazel-Zarandi, Asli Celikyilmaz*, **“Shepherd: A critic for language model generation”** [[HOME Page]](https://arxiv.org/abs/2308.04592) [[PDF]](https://arxiv.org/pdf/2308.04592)



*Zhenran Xu, Senbao Shi, Baotian Hu, Jindi Yu, Dongfang Li, Min Zhang, Yuxiang Wu*, **“Towards reasoning in large language models via multi-agent peer review collaboration”** [[HOME Page]](https://arxiv.org/abs/2311.08152) [[PDF]](https://arxiv.org/pdf/2311.08152)



*Qintong Li, Leyang Cui, Lingpeng Kong, Wei Bi*, **"Collaborative Evaluation: Exploring the Synergy of Large Language Models and Humans for Open-ended Generation Evaluation"** [[HOME Page]](https://arxiv.org/abs/2310.19740v1) [[PDF]](https://arxiv.org/pdf/2310.19740v1)